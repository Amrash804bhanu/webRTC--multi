## Real-time WebRTC VLM Multi-Object Detection
A reproducible demo performing real-time multi-object detection on live video streamed from a phone via WebRTC, overlaying results in near real-time.

## One-line Goal: 
Build a reproducible demo that performs real-time multi-object detection on live video streamed from a phone via WebRTC, returns detection bounding boxes + labels to the browser, overlays them in near real-time, and deliver a 1-minute Loom video showing the live demo, metrics, and one-sentence tradeoffs.

üìã ## Table of Contents
üì¶ Deliverables

‚ú® Features

üöÄ Quick Start (One Command)

Prerequisites

1. Clone the repository

2. Add Your ONNX Model

3. Start the Demo

4. Connect Your Phone

Troubleshooting Phone Connectivity (using ngrok)

üìä Benchmarking

‚ö†Ô∏è Troubleshooting Tips

üìÑ Appendix: Project Design Report

üí° Design Choices

üîã Low-Resource Mode

üõë Backpressure Policy

üì¶ Deliverables
This repository provides the following exact deliverables for the Real-time WebRTC VLM Multi-Object Detection project:

Git Repository: Contains the complete frontend and optional backend server code, along with Dockerfiles and docker-compose.yml for local execution.

start.sh: A convenient shell script to simplify launching the demo locally with a single command.

README.md: This document, providing comprehensive one-command start instructions, details on switching between operating modes, and clear guidelines for phone connectivity.

metrics.json: A JSON file generated by a short 30-second benchmark run, listing median & P95 end-to-end latency, processed frames per second (FPS), and uplink/downlink kilobits per second (kbps).

## 1-minute Loom Video: 

Phone ‚Üí browser live overlay of detections.

Brief display of metrics output.

A one-sentence improvement for future development.

report.md: A short, one-page report (included as an appendix within this README) explaining the project's design choices, low-resource mode implementation, and backpressure policy.

## Features
Real-time WebRTC Streaming: Enables live video streaming from a standard phone browser to the demo application without custom native apps.

Multi-Object Detection: Integrates Visual Language Model (VLM) capabilities to detect multiple objects within the live video stream.

Near Real-time Overlay: Returns detection bounding boxes and labels to the browser, overlaying them directly on the video feed with precise alignment.

Dual Operating Modes:

## WASM Mode: Performs inference directly on the client-side using onnxruntime-web, providing a low-resource path runnable on modest laptops (no GPU required). This mode includes quantized small models, input downscaling to 320x240, and adaptive sampling (10‚Äì15 FPS).

## Server Mode: Offloads inference to a Python backend, allowing for potentially larger models and centralized processing.

Automated Metrics Collection: Generates a metrics.json file with key performance indicators after a benchmark run.

Reproducible Local Environment: Utilizes Docker and Docker Compose for easy, consistent setup and execution.

User Experience (UX) & API Contract: Uses a standardized JSON message format for detection results (frame_id, capture_ts, recv_ts, inference_ts, detections with normalized coordinates), allowing the browser to align overlays and compute end-to-end latency.

## Quick Start (One Command)
Prerequisites
Ensure you have the following installed on your Windows machine:

Docker Desktop for Windows: Download & Install Docker Desktop

Important: Ensure Docker Desktop is running and fully initialized before proceeding.

Git for Windows: This package includes Git Bash, which is essential for running the provided .sh scripts.

1. Clone the repository
Open Git Bash and execute the following commands:

git clone https://github.com/Amrash804bhanu/webRTC--multi.git
cd webRTC--multi

2. Add Your ONNX Model
Download a small, quantized object detection model (e.g., yolov5n.onnx) and place it in the models/ directory:

./models/yolov5n.onnx

Note: You may need to adjust the preprocessing and post-processing logic within src/frontend/app.js (for WASM mode) and src/backend/server.py (for Server mode) to match the specific input/output requirements of your chosen ONNX model.

3. Start the Demo
Choose your preferred operating mode. This command will automatically build (if necessary) and launch the required Docker containers.

WASM Mode (Browser-side inference, low-resource friendly):

./start.sh

This is the default mode if no --mode flag is specified. It primarily starts the frontend service.

Server Mode (Server-side inference):

./start.sh --mode=server

4. Connect Your Phone
Open your laptop's web browser (Chrome is recommended for best compatibility) and navigate to:

http://localhost:3000

On the web page, click the "Start Stream" button. A QR code and the direct URL will be displayed.

Scan the displayed QR code with your mobile phone's camera, or manually type the URL into your phone's browser (Chrome on Android or Safari on iOS are recommended).

Allow camera access when prompted by your phone's browser.

You should immediately see your phone's live video stream mirrored on your laptop screen, with real-time bounding box overlays appearing on the detected objects.

## Troubleshooting Phone Connectivity (using ngrok)
If your phone cannot reach your laptop directly (e.g., due to Wi-Fi network configuration, firewall, or NAT restrictions), you can use ngrok to expose your localhost to a public URL.

## Download ngrok: Go to ngrok.com/download and download the Windows executable.

## Place ngrok.exe: Move the downloaded ngrok.exe file into your project's root directory (webRTC--multi/).

Run ngrok: Open a separate Git Bash/CMD/PowerShell window (keep your start.sh window running) and execute:

./ngrok http 3000

Ngrok will provide a public HTTPS URL (e.g., https://xxxx.ngrok-free.app). Use this public URL on your phone's browser instead of http://localhost:3000.

## üìä Benchmarking
To collect performance metrics over a 30-second run, follow these steps:

Ensure the application is already running (either in WASM or Server mode) and your phone is actively streaming video to the demo.

Open another Git Bash window in your project's root directory.

Run the bench script, specifying the desired duration and mode:

# To collect metrics for 30 seconds in WASM mode
./bench/run_bench.sh --duration 30 --mode wasm

# To collect metrics for 30 seconds in Server mode
./bench/run_bench.sh --duration 30 --mode server

After the script completes, a metrics.json file will be generated in your project's root directory. This file will contain:

median_e2e_latency_ms

p95_e2e_latency_ms

processed_fps

uplink_kbps

downlink_kbps

## ‚ö†Ô∏è Troubleshooting Tips
docker / docker compose command not found:

Ensure Docker Desktop is running on your system.

Verify that C:\Program Files\Docker\Docker\resources\bin is correctly added to your Windows system's Path environment variable. Remember to close and reopen your Git Bash terminal after modifying system environment variables.

unable to get image ... unexpected end of JSON input:

This usually indicates a stalled Docker process. Right-click the Docker whale icon in your system tray and select Quit Docker Desktop.

Open Command Prompt as Administrator and run taskkill /F /IM "com.docker.cli.exe" and taskkill /F /IM "docker.exe" to forcefully terminate any lingering Docker processes. Then, restart Docker Desktop.

unable to prepare context: path ".../docker/backend" not found:

Confirm that the docker/backend folder physically exists within your docker directory in the project structure.

Ensure you are executing the start.sh command from the absolute root of your project directory (webRTC--multi/).

failed to solve: process "/bin/sh -c apt-get update" did not complete successfully: exit code: 100:

This is a network connectivity issue from within the Docker container to the Linux package repositories.

Ensure your host machine has a stable internet connection.

Restart Docker Desktop.

Try rebuilding specifically with docker compose build --no-cache backend to bypass any corrupted cache.

Phone won't connect / QR code not showing / Video stream blank:

Ensure your phone and laptop are on the same local Wi-Fi network.

If on different networks or behind a strict router, use ngrok as detailed above.

Check your laptop browser's developer console (F12) for JavaScript errors (e.g., NotAllowedError if camera access was denied, or WebSocket connection failures).

Verify the id="localUrl" correction in your src/frontend/index.html and confirm that generateQrCode() is called within the startButton's click event listener in src/frontend/app.js.

Overlays are misaligned:

Confirm that capture_ts from the detection results JSON is correctly being used by the browser to synchronize overlays with the video frames.

Double-check that your ONNX model's output format is correctly parsed and that the drawBBoxes function correctly converts the normalized [0..1] coordinates to pixel values based on the video's actual dimensions.

## High CPU Usage:

Ensure you are running in WASM mode (if local resources are limited).

Verify that you are using a small, quantized ONNX model (e.g., YOLOv5n or MobileNet-SSD quantized).

Confirm that the input video frames are being downscaled to 320x240 and frame thinning (targeting 10-15 FPS) is actively implemented in your JavaScript and Python code to manage the processing load.

Utilize Chrome DevTools' Performance tab or Windows Task Manager to monitor resource consumption.

WebRTC Debugging: For detailed WebRTC diagnostics, open chrome://webrtc-internals in your Chrome browser on the laptop. This tool provides extensive statistics about your peer connections, ICE candidates, and data flow.

üìÑ Appendix: Project Design Report
## report.md - https://docs.google.com/document/d/1qb3KsyRaVu-ylANeeXHPKdbnPnWkCGdcxjL_MIWZuWc/edit?tab=t.0
